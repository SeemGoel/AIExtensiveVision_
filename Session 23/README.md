## Session 23

## Project Title: CLIP-Based Image Retrieval using Gradio Interface
##### Project Overview
This project demonstrates how to use the CLIP (Contrastive Languageâ€“Image Pretraining) model to perform image retrieval from a corpus based on user-defined textual input. The project leverages the capabilities of the CLIP model, which is designed to understand images and text in a unified manner, to match user-provided text descriptions with the most relevant images in the corpus. A Gradio interface is used to create an interactive web application where users can input their descriptions and view the matching images.

#####  Key Features
- CLIP Model Integration: Utilizes the pre-trained CLIP model from OpenAI for image-text matching.
- Image Corpus: Supports a directory of images to be used for retrieval.
- Interactive Interface: Provides an easy-to-use Gradio interface for users to input text and view the corresponding images.
- Text-to-Image Retrieval: Computes the similarity between text descriptions and images to find and display the best matches.

##### Huggingface demo:
https://huggingface.co/spaces/SeemG/TextToImageFlickrSearch


![image](https://github.com/user-attachments/assets/829d78a2-9f46-48d9-88f6-186361147017)



This work was inspired by the research of [Moein Shariatnia](https://towardsdatascience.com/simple-implementation-of-openai-clip-model-a-tutorial-ace6ff01d9f2)

